\cite{Stojnic2009a} demonstrated that the conventional NSP can be generalised to block-sparse representation. 
By proposing the following condition, they showed the equivalence of the optimisation problems $P_{2,1}$ and $P_{2,0}$:
\begin{gather*}
Q_{2,1}\myparanthese{S_b\myparanthese{\mybeta},\myPhi} \myeq \max_{\boldsymbol{x} \in \myKerMath \backslash\left\{\boldsymbol{0}\right\}} \frac{\displaystyle\sum_{k \in S_b\myparanthese{\mybeta}} \myabs{\displaystyle\sum_{j=1}^{d} \myabs{x_{j}[k]} ^{2}} ^{\frac{1}{2}}}{\displaystyle\sum_{k=1}^{K} \myabs{\displaystyle\sum_{j=1}^{d} \myabs{x_{j}[k]} ^{2}} ^{\frac{1}{2}}} < \frac12,
\end{gather*}
where, $S_b(\mybeta)$ is subset of a set with all subset of size $k$ of $\{1, \cdots , K\}$, i.e., block $k$-sparse representation, and $d$ is the length of equally-sized blocks.
Also, he mentioned that his result can be generalised to $P_{2,p}$, $0 \sless p \sleq 1$.